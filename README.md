# SuperDataScientist
ensayo que reÃºne varios modelos para anÃ¡lisis de datos y data science

Tiene un instalador automatico con las bibliotecas basicas, y algunas opcionales.

py install_dependencies.py
============================================================
  AutoML NLP - Instalador Inteligente
============================================================

ğŸ” Verificando dependencias...

âœ… nltk
âœ… scikit-learn
âœ… pandas
âœ… numpy
âœ… matplotlib
âœ… seaborn
âœ… xgboost
âœ… wordcloud
âœ… imbalanced-learn
âœ… lightgbm
âœ… catboost
âœ… reportlab
âœ… pillow
âœ… joblib
âš ï¸  pytorch (opcional)
âœ… transformers
âœ… tensorflow
âœ… keras

============================================================

âœ… Todos los paquetes esenciales ya estÃ¡n instalados

ğŸ’¡ Hay 1 paquetes opcionales disponibles:
   - pytorch

Â¿Deseas instalar los paquetes opcionales? (s/n): s

ğŸ“¦ Instalando paquetes opcionales...

â–¶ pytorch...    Instalando pytorch...


ğŸ“š Descargando recursos de NLTK...
   âœ… punkt
   âœ… stopwords
   âœ… wordnet
   âœ… averaged_perceptron_tagger

============================================================
  RESUMEN DE INSTALACIÃ“N
============================================================

âœ… Paquetes instalados: 18/18

ğŸ‰ Â¡InstalaciÃ³n completada exitosamente!

Ahora puedes ejecutar el script AutoML:
---python automl2.0.py---
   
âœ… Detecta automÃ¡ticamente quÃ© librerÃ­as estÃ¡n instaladas
âœ… Muestre mensajes claros de quÃ© falta y cÃ³mo instalarlo
âœ… Desactive automÃ¡ticamente funcionalidades que requieren librerÃ­as faltantes

py automl2.0.py

1-Carga y valida los datos.
2-Preprocesa los textos.
3-Analiza la frecuencia de palabras (para visualizaciones).
4-Prepara los conjuntos de entrenamiento y prueba.
5-Balancea las clases (si se especificÃ³).
6-Entrena los modelos y selecciona el mejor.
7-Genera el dashboard con todas las visualizaciones.
8-Exporta el modelo entrenado.

============================================================
âš™ï¸  CONFIGURACIÃ“N DEL SISTEMA AUTOML
============================================================

    CaracterÃ­sticas Disponibles:
    âœ… 16+ Modelos de Machine Learning
    âœ… Hyperparameter Tuning AutomÃ¡tico (GridSearchCV)
    âœ… 5 MÃ©todos de Balanceo de Clases
    âœ… 7 MÃ©tricas Avanzadas
    âœ… 12 Visualizaciones
    âœ… ExportaciÃ³n AutomÃ¡tica (PNG/PDF)
    âœ… Reporte PDF Completo
    âœ… AnÃ¡lisis de Palabras Frecuentes
    âœ… WordClouds por Clase

    CaracterÃ­sticas Opcionales (requieren instalaciÃ³n adicional):
    âš ï¸  3 Modelos de Deep Learning (LSTM, CNN, Bi-LSTM) - Requiere PyTorch/TensorFlow

âœ… Deep Learning disponible

ğŸ’¡ ConfiguraciÃ³n seleccionada:
   - Balanceo de clases: smote
   - Hyperparameter tuning: True
   - Deep Learning: False
   - MÃ©tricas: f1_score, balanced_accuracy, matthews_corrcoef
 Cargando datos...
   Total de registros: 40
   Columna de texto: 'texto'
   Columna de etiquetas: 'sentimiento'
   âœ“ Datos cargados: 40 registros vÃ¡lidos
   DistribuciÃ³n de clases:
sentimiento
positivo    20
negativo    20
Name: count, dtype: int64

ğŸ”§ Preprocesando textos...
   - Limpieza de texto
   - ConversiÃ³n a minÃºsculas
   - TokenizaciÃ³n
   - EliminaciÃ³n de puntuaciÃ³n
   - EliminaciÃ³n de stop words
   - LematizaciÃ³n

   âœ“ Preprocesamiento completado
   Longitud promedio original: 1.0 palabras
   Longitud promedio procesado: 1.0 palabras

ğŸ“¦ Preparando conjuntos de datos...
   ProporciÃ³n de prueba: 20.0%
   Aplicando vectorizaciÃ³n TF-IDF...
   âœ“ Conjuntos preparados:
   Entrenamiento: 32 muestras
   Prueba: 8 muestras
   CaracterÃ­sticas: 2 features
   Clases detectadas: ['negativo', 'positivo']

ğŸ¤– Entrenando modelos de ML...
============================================================
   Total de modelos a entrenar: 16

ğŸ”¹ Entrenando Logistic Regression...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Ridge Classifier...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando SGD Classifier...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Multinomial NB...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Bernoulli NB...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando SVM (Linear)...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando SVM (RBF)...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Decision Tree...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Random Forest...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Extra Trees...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Gradient Boosting...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando AdaBoost...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando XGBoost...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando KNN (k=5)...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando LightGBM...
   Metrics:
   - accuracy: 0.5000
   - f1_score: 0.3333
   - balanced_accuracy: 0.5000

ğŸ”¹ Entrenando CatBoost...
   âš ï¸  Error entrenando CatBoost: The following error was raised: 'CatBoostClassifiier' object has no attribute '__sklearn_tags__'. It seems that there are no classes that implement `__sklearn_tags__` in the MRO and/or all classes in the MRO call `super().__sklearn_tags__()`. Make sure to inherit from `BaseEstimator` which implements `__sklearn_tags__` (or alternatively define `__sklearn_tags__` but we don't recommend this approach). Note that `BaseEstimator` needs to be on the right side of other Mixins in the inheritance order.

============================================================
ğŸ† SELECCIÃ“N AUTOMÃTICA DEL MEJOR MODELO
============================================================

âœ¨ Mejor modelo seleccionado: Logistic Regression
   Criterio de selecciÃ³n: accuracy

   ğŸ“Š MÃ©tricas del mejor modelo:
   - accuracy: 1.0000
   - precision: 1.0000
   - recall: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000
   - matthews_corrcoef: 1.0000
   - cohen_kappa: 1.0000

   ğŸ¥‡ Top 5 modelos por accuracy:
   1. Logistic Regression: 1.0000
   2. Ridge Classifier: 1.0000
   3. SGD Classifier: 1.0000
   4. Multinomial NB: 1.0000
   5. Bernoulli NB: 1.0000
âœ“ train_models completed

ğŸ“Š Generando dashboard de resultados...

<img width="1366" height="655" alt="DashBoard" src="https://github.com/user-attachments/assets/e1874b73-e541-4b8d-a5e6-aa6871b2c999" />

============================================================
ğŸ“‹ REPORTE DE CLASIFICACIÃ“N - MEJOR MODELO
============================================================
              precision    recall  f1-score   support

    negativo     1.0000    1.0000    1.0000         4
    positivo     1.0000    1.0000    1.0000         4

    accuracy                         1.0000         8
   macro avg     1.0000    1.0000    1.0000         8
weighted avg     1.0000    1.0000    1.0000         8
