# SuperDataScientist
ensayo que reÃºne varios modelos para anÃ¡lisis de datos y data science

Tiene un instalador automatico con las bibliotecas basicas, y algunas opcionales.

py install_dependencies.py
============================================================
  AutoML NLP - Instalador Inteligente
============================================================

ğŸ” Verificando dependencias...

âœ… nltk
âœ… scikit-learn
âœ… pandas
âœ… numpy
âœ… matplotlib
âœ… seaborn
âœ… xgboost
âœ… wordcloud
âœ… imbalanced-learn
âœ… lightgbm
âœ… catboost
âœ… reportlab
âœ… pillow
âœ… joblib
âš ï¸  pytorch (opcional)
âœ… transformers
âœ… tensorflow
âœ… keras

============================================================

âœ… Todos los paquetes esenciales ya estÃ¡n instalados

ğŸ’¡ Hay 1 paquetes opcionales disponibles:
   - pytorch

Â¿Deseas instalar los paquetes opcionales? (s/n): s

ğŸ“¦ Instalando paquetes opcionales...

â–¶ pytorch...    Instalando pytorch...


ğŸ“š Descargando recursos de NLTK...
   âœ… punkt
   âœ… stopwords
   âœ… wordnet
   âœ… averaged_perceptron_tagger

============================================================
  RESUMEN DE INSTALACIÃ“N
============================================================

âœ… Paquetes instalados: 18/18

ğŸ‰ Â¡InstalaciÃ³n completada exitosamente!

Ahora puedes ejecutar el script AutoML:
---python automl2.0.py---
   
âœ… Detecta automÃ¡ticamente quÃ© librerÃ­as estÃ¡n instaladas
âœ… Muestre mensajes claros de quÃ© falta y cÃ³mo instalarlo
âœ… Desactive automÃ¡ticamente funcionalidades que requieren librerÃ­as faltantes

py automl2.0.py

1-Carga y valida los datos.
2-Preprocesa los textos.
3-Analiza la frecuencia de palabras (para visualizaciones).
4-Prepara los conjuntos de entrenamiento y prueba.
5-Balancea las clases (si se especificÃ³).
6-Entrena los modelos y selecciona el mejor.
7-Genera el dashboard con todas las visualizaciones.
8-Exporta el modelo entrenado.

============================================================
âš™ï¸  CONFIGURACIÃ“N DEL SISTEMA AUTOML
============================================================

    CaracterÃ­sticas Disponibles:
    âœ… 16+ Modelos de Machine Learning
    âœ… Hyperparameter Tuning AutomÃ¡tico (GridSearchCV)
    âœ… 5 MÃ©todos de Balanceo de Clases
    âœ… 7 MÃ©tricas Avanzadas
    âœ… 12 Visualizaciones
    âœ… ExportaciÃ³n AutomÃ¡tica (PNG/PDF)
    âœ… Reporte PDF Completo
    âœ… AnÃ¡lisis de Palabras Frecuentes
    âœ… WordClouds por Clase

    CaracterÃ­sticas Opcionales (requieren instalaciÃ³n adicional):
    âš ï¸  3 Modelos de Deep Learning (LSTM, CNN, Bi-LSTM) - Requiere PyTorch/TensorFlow

âœ… Deep Learning disponible

ğŸ’¡ ConfiguraciÃ³n seleccionada:
   - Balanceo de clases: smote
   - Hyperparameter tuning: True
   - Deep Learning: False
   - MÃ©tricas: f1_score, balanced_accuracy, matthews_corrcoef
 Cargando datos...
   Total de registros: 40
   Columna de texto: 'texto'
   Columna de etiquetas: 'sentimiento'
   âœ“ Datos cargados: 40 registros vÃ¡lidos
   DistribuciÃ³n de clases:
sentimiento
positivo    20
negativo    20
Name: count, dtype: int64

ğŸ”§ Preprocesando textos...
   - Limpieza de texto
   - ConversiÃ³n a minÃºsculas
   - TokenizaciÃ³n
   - EliminaciÃ³n de puntuaciÃ³n
   - EliminaciÃ³n de stop words
   - LematizaciÃ³n

   âœ“ Preprocesamiento completado
   Longitud promedio original: 1.0 palabras
   Longitud promedio procesado: 1.0 palabras

ğŸ“¦ Preparando conjuntos de datos...
   ProporciÃ³n de prueba: 20.0%
   Aplicando vectorizaciÃ³n TF-IDF...
   âœ“ Conjuntos preparados:
   Entrenamiento: 32 muestras
   Prueba: 8 muestras
   CaracterÃ­sticas: 2 features
   Clases detectadas: ['negativo', 'positivo']

ğŸ¤– Entrenando modelos de ML...
============================================================
   Total de modelos a entrenar: 16

ğŸ”¹ Entrenando Logistic Regression...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Ridge Classifier...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando SGD Classifier...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Multinomial NB...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Bernoulli NB...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando SVM (Linear)...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando SVM (RBF)...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Decision Tree...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Random Forest...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Extra Trees...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando Gradient Boosting...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando AdaBoost...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando XGBoost...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando KNN (k=5)...
   Metrics:
   - accuracy: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000

ğŸ”¹ Entrenando LightGBM...
   Metrics:
   - accuracy: 0.5000
   - f1_score: 0.3333
   - balanced_accuracy: 0.5000

ğŸ”¹ Entrenando CatBoost...
   âš ï¸  Error entrenando CatBoost: The following error was raised: 'CatBoostClassifiier' object has no attribute '__sklearn_tags__'. It seems that there are no classes that implement `__sklearn_tags__` in the MRO and/or all classes in the MRO call `super().__sklearn_tags__()`. Make sure to inherit from `BaseEstimator` which implements `__sklearn_tags__` (or alternatively define `__sklearn_tags__` but we don't recommend this approach). Note that `BaseEstimator` needs to be on the right side of other Mixins in the inheritance order.

============================================================
ğŸ† SELECCIÃ“N AUTOMÃTICA DEL MEJOR MODELO
============================================================

âœ¨ Mejor modelo seleccionado: Logistic Regression
   Criterio de selecciÃ³n: accuracy

   ğŸ“Š MÃ©tricas del mejor modelo:
   - accuracy: 1.0000
   - precision: 1.0000
   - recall: 1.0000
   - f1_score: 1.0000
   - balanced_accuracy: 1.0000
   - matthews_corrcoef: 1.0000
   - cohen_kappa: 1.0000

   ğŸ¥‡ Top 5 modelos por accuracy:
   1. Logistic Regression: 1.0000
   2. Ridge Classifier: 1.0000
   3. SGD Classifier: 1.0000
   4. Multinomial NB: 1.0000
   5. Bernoulli NB: 1.0000
âœ“ train_models completed

ğŸ“Š Generando dashboard de resultados...

<img width="1366" height="655" alt="DashBoard" src="https://github.com/user-attachments/assets/e1874b73-e541-4b8d-a5e6-aa6871b2c999" />

============================================================
ğŸ“‹ REPORTE DE CLASIFICACIÃ“N - MEJOR MODELO
============================================================
              precision    recall  f1-score   support
    negativo     1.0000    1.0000    1.0000         4
    positivo     1.0000    1.0000    1.0000         4

    accuracy                         1.0000         8
   macro avg     1.0000    1.0000    1.0000         8
weighted avg     1.0000    1.0000    1.0000         8
============================================================


Para datasets mas grades seleccion de dos modelos entre los 16
ğŸ“ Iniciando AutoML - Comparador de 2 Modelos
ğŸš€ VersiÃ³n optimizada para VELOCIDAD


==========================================================================================
âš™ï¸  CONFIGURACIÃ“N
==========================================================================================
Â¿Usar dataset propio (CSV)? (s/N): s
âœ… Cargado:  df_limpio.csv (419827 filas)

ğŸ“Š Dataset: 419827 filas
   Columna de texto: 'texto'
   Columna de etiqueta: 'polaridad'

   DistribuciÃ³n de clases:
      positivo: 225279 (53.7%)
      neutro: 133534 (31.8%)
      negativo: 61014 (14.5%)

==========================================================================================
ğŸ¤– MODELOS DISPONIBLES EN AutoML
==========================================================================================

ğŸ“Œ Selecciona 2 modelos diferentes para comparar

#   Modelo                    DescripciÃ³n                              Velocidad       PrecisiÃ³n    

--------------------------------------------------------------------------------------------------  
1   Logistic Regression       âš¡ Modelo lineal rÃ¡pido y confiable       âš¡âš¡âš¡ Muy rÃ¡pido  â­â­â­ Bueno
2   Ridge Classifier          âš¡ RegularizaciÃ³n L2, versiÃ³n lineal robusta âš¡âš¡âš¡ Muy rÃ¡pido  â­â­â­ Bueno
3   SGD Classifier            âš¡ Descenso de gradiente estocÃ¡stico      âš¡âš¡âš¡ Muy rÃ¡pido  â­â­â­ Bueno
4   Multinomial NB            ğŸ“Š ProbabilÃ­stico, ideal para conteos de palabras âš¡âš¡âš¡ Muy rÃ¡pido   â­â­â­ Bueno para NLP
5   Bernoulli NB              ğŸ“Š ProbabilÃ­stico para caracterÃ­sticas binarias âš¡âš¡âš¡ Muy rÃ¡pido  â­ â­ Aceptable
6   SVM (Linear)              ğŸ¯ MÃ¡quinas de soporte vectorial (kernel lineal) âš¡âš¡ RÃ¡pido       â­ â­â­â­ Excelente
7   SVM (RBF)                 ğŸ¯ MÃ¡quinas de soporte vectorial (kernel RBF) âš¡ MÃ¡s lento     â­â­â­ â­ Muy bueno
8   Decision Tree             ğŸŒ³ Ãrbol de decisiÃ³n simple e interpretable âš¡âš¡âš¡ Muy rÃ¡pido  â­â­â­ Bueno
9   Random Forest             ğŸŒ² Ensemble de Ã¡rboles paralelos          âš¡âš¡ RÃ¡pido       â­â­â­â­ Muy bueno
10  Extra Trees               ğŸŒ² Arboles extra aleatorizados (aÃºn mÃ¡s rÃ¡pido) âš¡âš¡ RÃ¡pido       â­â­â­â­ Muy bueno
11  Gradient Boosting         ğŸš€ Boosting secuencial, excelente precisiÃ³n âš¡âš¡ RÃ¡pido       â­â­â­â­â­ Excelente
12  AdaBoost                  ğŸš€ Adaptive Boosting, robusto             âš¡âš¡ RÃ¡pido       â­â­â­â­ Muy bueno
13  XGBoost                   âš¡ğŸš€ Boosting ultra-optimizado, MÃS RÃPIDO âš¡âš¡ RÃ¡pido       â­â­â­â­ â­ Excelente
14  KNN (k=5)                 ğŸ“ K-Nearest Neighbors, simple            âš¡ Lento en test â­â­â­ Bueno
15  LightGBM                  ğŸ’¡ Boosting ultra-ligero, MÃS RÃPIDO que XGBoost âš¡âš¡âš¡ Muy rÃ¡pido  â­â­â­â­â­ Excelente
16  CatBoost                  ğŸ± Boosting con manejo automÃ¡tico de categorÃ­as âš¡âš¡ RÃ¡pido       â­â­â­â­â­ Excelente

------------------------------------------------------------------------------------------
ğŸ’¡ RECOMENDACIONES RÃPIDAS:
   - Para MÃXIMA VELOCIDAD: elige 'Logistic Regression' y 'XGBoost'
   - Para MÃXIMA PRECISIÃ“N: elige 'Gradient Boosting' y 'XGBoost'
   - BALANCEADO: 'Logistic Regression' y 'Random Forest'
------------------------------------------------------------------------------------------

ğŸ”½ Selecciona el MODELO #1 (1-16): 1

   âœ… 'Logistic Regression' seleccionado
      âš¡ Modelo lineal rÃ¡pido y confiable
      âš¡âš¡âš¡ Muy rÃ¡pido | â­â­â­ Bueno

ğŸ”½ Selecciona el MODELO #2 (1-16): 12

   âœ… 'AdaBoost' seleccionado
      ğŸš€ Adaptive Boosting, robusto
      âš¡âš¡ RÃ¡pido | â­â­â­â­ Muy bueno

==========================================================================================
âœ… MODELOS SELECCIONADOS
==========================================================================================

1. Logistic Regression
   ğŸ“ âš¡ Modelo lineal rÃ¡pido y confiable
   âš¡ Velocidad: âš¡âš¡âš¡ Muy rÃ¡pido
   ğŸ¯ PrecisiÃ³n: â­â­â­ Bueno

2. AdaBoost
   ğŸ“ ğŸš€ Adaptive Boosting, robusto
   âš¡ Velocidad: âš¡âš¡ RÃ¡pido
   ğŸ¯ PrecisiÃ³n: â­â­â­â­ Muy bueno

==========================================================================================
âš™ï¸  INICIALIZANDO SISTEMA AUTOML
==========================================================================================

ğŸ”§ ConfiguraciÃ³n:
   - Lenguaje:  EspaÃ±ol
   - Test size: 20%
   - Balanceo de clases:  SMOTE
   - Hiperparameter tuning:  DESACTIVADO (para velocidad)
   - Deep Learning:  DESACTIVADO (para velocidad)

==========================================================================================
ğŸš€ EJECUTANDO PIPELINE
==========================================================================================
ğŸ“Š Cargando datos...
   Total de registros: 419827
   Columna de texto: 'texto'
   Columna de etiquetas: 'polaridad'
   âœ“ Datos cargados: 419827 registros vÃ¡lidos
   DistribuciÃ³n de clases:
polaridad
positivo    225279
neutro      133534
negativo     61014
Name: count, dtype: int64

ğŸ”§ Preprocesando textos...
   - Limpieza de texto
   - ConversiÃ³n a minÃºsculas
   - TokenizaciÃ³n
   - EliminaciÃ³n de puntuaciÃ³n
   - EliminaciÃ³n de stop words
   - LematizaciÃ³n...
